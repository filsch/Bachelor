library(geoR); library(MASS); library(akima); library(fields); library(RSAGA)
#Adapting data from matrix form, to original + square 50x50
original_mapping = grid.to.xyz(t(volcano))
#Constructing square mapping with adapted axes.
square_mapping = interp(x = original_mapping$x, y = original_mapping$y, z = original_mapping$z,
xo = seq(1,max(original_mapping$x),length.out = 50),
yo = seq(1,max(original_mapping$y),length.out = 50))
square_mapping$x = seq(50); square_mapping$y = seq(50)
#Constructing isotropic correlation matrix. Now using Exponential
corr_matrix <- function(pred_points, sample_points, range){
ncolumns = dim(pred_points)[1]; nrows = dim(sample_points)[1]
corr_matrix = matrix(numeric(nrows*ncolumns),nrow=nrows)
for (i in 1:ncolumns){
corr_matrix[,i] = sqrt( rowSums((sample_points - matrix(numeric(2*nrows) + 1,ncol=2)%*%diag(pred_points[i,]))^2) )
}
return( Exponential(corr_matrix, range = range) )
}
prior_field = expand.grid(seq(10), seq(10))
image.plot(square_mapping)
image.plot(original_mapping)
image.plot(square_mapping)
library(geoR); library(MASS); library(akima); library(fields); library(RSAGA)
set.seed(4545)
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
#Constructing square mapping with adapted axes to a 50x50
#square_mapping = expand.grid(x = seq(1, 50), y= seq(1,50))
square_mapping = interp(x = original_mapping$x, y = original_mapping$y, z = original_mapping$z,
xo = seq(1,max(original_mapping$x),length.out = 50),
yo = seq(1,max(original_mapping$y),length.out = 50))
square_mapping$x = seq(0,50); square_mapping$y = seq(0,50)
#Constructing isotropic correlation matrix. Now using Exponential
corr_matrix <- function(pred_points, sample_points, range){
ncolumns = dim(pred_points)[1]; nrows = dim(sample_points)[1]
corr_matrix = matrix(numeric(nrows*ncolumns),nrow=nrows)
for (i in 1:ncolumns){
corr_matrix[,i] = sqrt( rowSums((sample_points - matrix(numeric(2*nrows) + 1,ncol=2)%*%diag(pred_points[i,]))^2) )
}
return( Exponential(corr_matrix, range = range) )
}
#Generating sample from grid by design
#Regular, 64 samples
grid_samples = expand.grid(x = seq(0, 50, 8), y= seq(0,50,8))
grid_samples$z = square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
#Assigning prior values and estimating beta
prior_field = expand.grid(seq(10), seq(10))
alpha = 5; beta = 0.5;
sigma2 = rgamma(1,alpha,beta); range = 1 + runif(1)*9
# beta = glm(grid_samples$z ~ grid_samples$x*grid_samples$y + I(grid_samples$x*grid_samples$x) + I(grid_samples$y*grid_samples$y))
#Computing the predictor:
prediction_grid = expand.grid(seq(50),seq(50))
posterior_kriger = krige.conv(coords=cbind(grid_samples$x,grid_samples$y), data=grid_samples$z, locations = prediction_grid,
krige=krige.control(type.krige= "OK", trend.d = "2nd", trend.l = "2nd", cov.model="exponential", cov.pars=c(sigma2, range)));
#Plotting some results
plot_values = list(z=matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE), x = seq(0,50), y = seq(0,50))
image.plot(plot_values, main="Kriging predictions, no noise on data Y", zlim=c(80,200))
plot_values$z = matrix(sqrt(posterior_kriger$krige.var),nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging std.dev., no noise on data Y", zlim=c(0,5))
plot_values$z = square_mapping$z - matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging differences", zlim=c(-30, 30))
#prior ranges; prior variance; prior field; numeric approximation integrat;
#exponential covariance func; matern?; squared exp?; different polynomial trends?;
#krigerestimate of posterior
#different designs
#multivariate normal for everything!
plot_values = list(z=matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE), x = seq(0,50), y = seq(0,50))
posterior_kriger = krige.conv(coords=cbind(grid_samples$x,grid_samples$y), data=grid_samples$z, locations = prediction_grid,
krige=krige.control(type.krige= "OK", trend.d = "2nd", trend.l = "2nd", cov.model="exponential", cov.pars=c(sigma2, range)));
posterior_kriger = krige.conv(coords=cbind(grid_samples$x,grid_samples$y), data=grid_samples$z, locations = prediction_grid,
krige=krige.control(type.krige= "OK", trend.d = "2nd", trend.l = "2nd", cov.model="exponential", cov.pars=c(sigma2, range)));
grid_samples$z = square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)
square_mapping$z
square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
length(square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
)
matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)
library(geoR); library(MASS); library(akima); library(fields); library(RSAGA)
set.seed(4545)
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
#Constructing square mapping with adapted axes to a 50x50
#square_mapping = expand.grid(x = seq(1, 50), y= seq(1,50))
square_mapping = interp(x = original_mapping$x, y = original_mapping$y, z = original_mapping$z,
xo = seq(1,max(original_mapping$x),length.out = 50),
yo = seq(1,max(original_mapping$y),length.out = 50))
square_mapping$x = seq(0,50); square_mapping$y = seq(0,50)
#Constructing isotropic correlation matrix. Now using Exponential
corr_matrix <- function(pred_points, sample_points, range){
ncolumns = dim(pred_points)[1]; nrows = dim(sample_points)[1]
corr_matrix = matrix(numeric(nrows*ncolumns),nrow=nrows)
for (i in 1:ncolumns){
corr_matrix[,i] = sqrt( rowSums((sample_points - matrix(numeric(2*nrows) + 1,ncol=2)%*%diag(pred_points[i,]))^2) )
}
return( Exponential(corr_matrix, range = range) )
}
#Generating sample from grid by design
#Regular, 64 samples
grid_samples = expand.grid(x = seq(1, 50, 8), y= seq(1,50,8))
grid_samples$z = square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
#Assigning prior values and estimating beta
prior_field = expand.grid(seq(10), seq(10))
alpha = 5; beta = 0.5;
sigma2 = rgamma(1,alpha,beta); range = 1 + runif(1)*9
# beta = glm(grid_samples$z ~ grid_samples$x*grid_samples$y + I(grid_samples$x*grid_samples$x) + I(grid_samples$y*grid_samples$y))
#Computing the predictor:
prediction_grid = expand.grid(seq(50),seq(50))
posterior_kriger = krige.conv(coords=cbind(grid_samples$x,grid_samples$y), data=grid_samples$z, locations = prediction_grid,
krige=krige.control(type.krige= "OK", trend.d = "2nd", trend.l = "2nd", cov.model="exponential", cov.pars=c(sigma2, range)));
#Plotting some results
plot_values = list(z=matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE), x = seq(0,50), y = seq(0,50))
image.plot(plot_values, main="Kriging predictions, no noise on data Y", zlim=c(80,200))
plot_values$z = matrix(sqrt(posterior_kriger$krige.var),nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging std.dev., no noise on data Y", zlim=c(0,5))
plot_values$z = square_mapping$z - matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging differences", zlim=c(-30, 30))
#prior ranges; prior variance; prior field; numeric approximation integrat;
#exponential covariance func; matern?; squared exp?; different polynomial trends?;
#krigerestimate of posterior
#different designs
#multivariate normal for everything!
par(mfrow=c(2,2))
plot_values = list(z=matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE), x = seq(0,50), y = seq(0,50))
image.plot(plot_values, main="Kriging predictions, no noise on data Y", zlim=c(80,200))
plot_values$z = matrix(sqrt(posterior_kriger$krige.var),nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging std.dev., no noise on data Y", zlim=c(0,5))
plot_values$z = square_mapping$z - matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging differences", zlim=c(-30, 30))
plot(gridsamples$x,grid_samlples$y, main="Observed points")
plot(grid_samples$x,grid_samples$y, main="Observed points")
library(geoR); library(MASS); library(akima); library(fields); library(RSAGA)
set.seed(4545)
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
#Constructing square mapping with adapted axes to a 50x50
#square_mapping = expand.grid(x = seq(1, 50), y= seq(1,50))
square_mapping = interp(x = original_mapping$x, y = original_mapping$y, z = original_mapping$z,
xo = seq(1,max(original_mapping$x),length.out = 50),
yo = seq(1,max(original_mapping$y),length.out = 50))
square_mapping$x = seq(0,50); square_mapping$y = seq(0,50)
#Constructing isotropic correlation matrix. Now using Exponential
corr_matrix <- function(pred_points, sample_points, range){
ncolumns = dim(pred_points)[1]; nrows = dim(sample_points)[1]
corr_matrix = matrix(numeric(nrows*ncolumns),nrow=nrows)
for (i in 1:ncolumns){
corr_matrix[,i] = sqrt( rowSums((sample_points - matrix(numeric(2*nrows) + 1,ncol=2)%*%diag(pred_points[i,]))^2) )
}
return( Exponential(corr_matrix, range = range) )
}
#Generating sample from grid by design
#Regular, 64 samples
grid_samples = expand.grid(x = seq(1, 50, 8), y= seq(1,50,8))
grid_samples$z = square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
#Assigning prior values and estimating beta
prior_field = expand.grid(seq(10), seq(10))
alpha = 5; beta = 0.5;
sigma2 = rgamma(1,alpha,beta); range = 1 + runif(1)*9
# beta = glm(grid_samples$z ~ grid_samples$x*grid_samples$y + I(grid_samples$x*grid_samples$x) + I(grid_samples$y*grid_samples$y))
#Computing the predictor:
prediction_grid = expand.grid(seq(50),seq(50))
posterior_kriger = krige.conv(coords=cbind(grid_samples$x,grid_samples$y), data=grid_samples$z, locations = prediction_grid,
krige=krige.control(type.krige= "OK", trend.d = "2nd", trend.l = "2nd", cov.model="exponential", cov.pars=c(sigma2, range)));
#Plotting some results
par(mfrow=c(2,2))
plot_values = list(z=matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE), x = seq(0,50), y = seq(0,50))
image.plot(plot_values, main="Kriging predictions, no noise on data Y", zlim=c(80,200))
plot_values$z = matrix(sqrt(posterior_kriger$krige.var),nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging std.dev., no noise on data Y", zlim=c(0,5))
plot_values$z = square_mapping$z - matrix(posterior_kriger$predict,nrow=50,ncol=50,byrow=FALSE)
image.plot(plot_values, main="Kriging vs actual", zlim=c(-30, 30))
plot(grid_samples$x,grid_samples$y, main="Observed points")
#prior ranges; prior variance; prior field; numeric approximation integrat;
#exponential covariance func; matern?; squared exp?; different polynomial trends?;
#krigerestimate of posterior
#different designs
#multivariate normal for everything!
?dgamma
dgamma(0.1,alpha,beta)
dgamma(0.2,alpha,beta)
dgamma(0.3,alpha,beta)
dgamma(0.4,alpha,beta)
dgamma(0.5,alpha,beta)
dgamma(7,alpha,beta)
pgamma(0.1,alpha,beta)
pgamma(0.2,alpha,beta)
pgamma(0.3,alpha,beta)
qgamma(0.1,alpha,beta)
qgamma(0.2,alpha,beta)
qgamma(0.3,alpha,beta)
qgamma(0.4,alpha,beta)
qgamma(0.5,alpha,beta)
qgamma(0.6,alpha,beta)
qgamma(0.7,alpha,beta)
qgamma(0.8,alpha,beta)
qgamma(0.9,alpha,beta)
qgamma(1,alpha,beta)
alpha*beta
alpha/beta
qgamma(0.4,alpha,beta)
qgamma(0.5,alpha,beta)
FOR (I IN 1:10){
CAT(QGAMMA(0.1*i))
}
for (i in 1:1)){}
for (i in 1:1)){
cat(qgamma(0.1*i,alpha,beta))
}
for (i in 1:1)){cat(qgamma(0.1*i, alpha,1/beta))}
for (i in 1:1){cat(qgamma(0.1*i, alpha,1/beta))}
for (i in 1:10){cat(qgamma(0.1*i, alpha,1/beta))}
for (i in 1:10){cat(qgamma(0.1*i, alpha,1/beta),'\n')}
for (i in 1:10){cat(qgamma(0.1*i, alpha,beta),'\n')}
curve(dgamma(x,shape=alpha,rate=beta))
curve(dgamma(x,shape=alpha,rate=beta),0,5)
curve(dgamma(x,shape=alpha,rate=beta),0,10)
curve(dgamma(x,shape=alpha,rate=beta),0,115)
curve(dgamma(x,shape=alpha,rate=beta),0,15)
qgamma(alpha/beta )
qgamma(alpha/beta,alpha,beta)
qgamma(,alpha,beta)
j+i
alpha/beta
dgamma(10,alpha,beta)
pgamma(alpha/beta + sqrt(alpha)/beta,alpha,beta)
pgamma(10,alpha,beta)
pgamma(alpha/beta + sqrt(alpha)/beta,alpha,beta) - pgamma(10,alpha,beta)
pgamma(alpha/beta + sqrt(alpha)/beta,alpha,beta) - pgamma(alpha/beta,alpha,beta)
2*pgamma(alpha/beta + sqrt(alpha)/beta,alpha,beta) - pgamma(alpha/beta,alpha,beta))
2*(pgamma(alpha/beta + sqrt(alpha)/beta,alpha,beta) - pgamma(alpha/beta,alpha,beta))
?pgamma
for (i in 1:10){
for (j in 1:10){
prior_field$x[j+i] = qgamma(0.1*i,alpha,beta)
prior_field$y[j+i] = 0.1
priofield$z[j+i] = 0.01
}
}
prior_field = expand.grid(seq(10), seq(10))
alpha = 5; beta = 0.5;
for (i in 1:10){
for (j in 1:10){
prior_field$x[j+i] = qgamma(0.1*i,alpha,beta)
prior_field$y[j+i] = 0.1
prior_field$z[j+i] = 0.01
}
}
for (i in 1:10){
for (j in 1:10){
prior_field$x[j+i] = qgamma(0.9*i,alpha,beta)
prior_field$y[j+i] = 0.1
prior_field$z[j+i] = 0.01
}
}
warnings()
for (i in 1:10){
for (j in 1:10){
prior_field$x[j+i] = qgamma(0.09*i,alpha,beta)
prior_field$y[j+i] = 0.1
prior_field$z[j+i] = 0.01
}
}
prior_field
rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
#Assigning prior values and estimating beta
prior_field = expand.grid(seq(10), seq(10))
alpha = 5; beta = 0.5;
#"Uniform"
prior_field$x = rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
prior_field$y = numeric(100) + 0.1
prior_field$z = numeric(100) + 0.01
prior_field
image.plot(prior_field)
image(prior_field)
image(prior_field)seq(-5:4)
image(prior_field)seq(-5:4)
seq(-5:4)
seq(-5:4, 1)
seq(-5,4)
values = seq(-5,4)*sqrt(alpha)/beta + alpha/beta
values
seq(-5,4)*0.4*sqrt(alpha)/beta
0.4*sqrt(alpha)/beta
0.2*sqrt(alpha)/beta
alpha/beta
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
values
?diff
diff(1:10)
pgamma(values,alpha,beta)
diff(pgamma(values,alpha,beta))
c(0.00022,diff(pgamma(values,alpha,beta)))
c(0.00022,diff(pgamma(values,alpha,beta))-0.00022)
sum(c(0.00022,diff(pgamma(values,alpha,beta))-0.00022))
sum(c(0.00022,diff(pgamma(values,alpha,beta))))
1 - sum(c(0.00022,diff(pgamma(values,alpha,beta))))
values
diff(values)
values + 0.5 diff(values)
values + 0.5*diff(values)
values[end]
end[values]
end(values)
lower = c(0, values[2:length(values)]); upper = c(values[1:length(values)-1],0)
lower = c(0, values[2:length(values)]); upper = c(values[1:length(values)-1],Inf)
upper
lower
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
lower
upper
prior_field$sigma2 = rep(values, times=10)
prior_field$sigma2
pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta)
sum(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
prior_field$sigma2 = rep(values, times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = 0.1*pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta)
image(prior_field)
prior_field$prob
pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta)
prior_field$prob = 0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
prior_field$prob
plot(prior_field$range, prior_field$prob)
image.plot(prior_field)
prior_field$x = rep(values, times=10)
prior_field$y = rep(seq(1:10), times=10)
prior_field$z = 0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
image.plot(prior_field)
contour(prior_field)
interp_prior = interp(x = prior_field$sigma2, y = prior_field$range, z = prior_field$prob)
?interp
interp_prior = interp(x = prior_field$sigma2, y = prior_field$range, z = prior_field$prob, duplicat="mean")
image.plot(interp_prior)
prior_field
prior_field = expand.grid(seq(10), seq(10))
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
prior_field$sigma2 = rep(values, times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = 0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
prior_field
prior_field$sigma2 = rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
alpha = 5; beta = 0.5;
prior_field$sigma2 = rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
prior_field = list()
prior_field$sigma2 = rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = numeric(100) + 0.01
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
prior_field$sigma2 = rep(values, times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = 0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
image.plot(prior_field)
image(prior_field)
interp_prior = interp(x = prior_field$sigma2, y = prior_field$range, z = prior_field$prob)
library(geoR); library(MASS); library(akima); library(fields); library(RSAGA)
set.seed(4545)
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
#Constructing square mapping with adapted axes to a 50x50
#square_mapping = expand.grid(x = seq(1, 50), y= seq(1,50))
square_mapping = interp(x = original_mapping$x, y = original_mapping$y, z = original_mapping$z,
xo = seq(1,max(original_mapping$x),length.out = 50),
yo = seq(1,max(original_mapping$y),length.out = 50))
square_mapping$x = seq(0,50); square_mapping$y = seq(0,50)
#Constructing isotropic correlation matrix. Now using Exponential
corr_matrix <- function(pred_points, sample_points, range){
ncolumns = dim(pred_points)[1]; nrows = dim(sample_points)[1]
corr_matrix = matrix(numeric(nrows*ncolumns),nrow=nrows)
for (i in 1:ncolumns){
corr_matrix[,i] = sqrt( rowSums((sample_points - matrix(numeric(2*nrows) + 1,ncol=2)%*%diag(pred_points[i,]))^2) )
}
return( Exponential(corr_matrix, range = range) )
}
#Generating sample from grid by design
#Regular, 64 samples
grid_samples = expand.grid(x = seq(1, 50, 8), y= seq(1,50,8))
grid_samples$z = square_mapping$z[matrix(cbind(grid_samples$x, grid_samples$y), nrow=49,ncol=2)]
#Assigning prior values and estimating beta
prior_field = list()
alpha = 5; beta = 0.5;
#"Uniform"
prior_field$sigma2 = rep(qgamma(0.09*seq(1:10),alpha,beta), times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = numeric(100) + 0.01
#Centre mean, 0.4*std indrement out from centre
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
prior_field$sigma2 = rep(values, times=10)
prior_field$range = rep(seq(1:10), times=10)
prior_field$prob = 0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta))
interp_prior = interp(x = prior_field$sigma2, y = prior_field$range, z = prior_field$prob)
prior_field$prob = rep(0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta)), times = 10)
interp_prior = interp(x = prior_field$sigma2, y = prior_field$range, z = prior_field$prob)
prior_field
values = seq(-5,4)*0.4*sqrt(alpha)/beta + alpha/beta
lower = c(0, values[2:length(values)] - 0.2*sqrt(alpha)/beta); upper = c(values[1:length(values)-1]  + 0.2*sqrt(alpha)/beta,Inf)
prior_field = expand.grid(sigma2=values, range = seq(1,10))
prior_field$prob = rep(0.1*(pgamma(upper, alpha,beta) - pgamma(lower,alpha,beta)), times = 10)
prior_field
image.plot(prior_field)
image.plot(x=prior_field$sigma2,y=prior_field$range, z = prior_field$prob)
image(x=prior_field$sigma2,y=prior_field$range, z = prior_field$prob)
image(prior_field)
prior_field
#Source auxilliary functions
source('~/Documents/Bachelor/myglm_lite.R')
set.seed(4545)
#TODO:
# - Lage flere funksjoner for oversiktlighet
# - Gjennoms??ke myglm_lite
# - Begynne ?? notere i latex
# - Koble prior med prediksjonen
# - Unders??ke hvorfor 'linear' og 'quadratic' gir tilsynelatende motsatt resultater
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
image.plot(original_mapping)
map = squareMap(original_mapping, 50)
#--------------------------------------------------------------------------------------------------------
#Constructing priorfield
prior = priorField(10,10)
#--------------------------------------------------------------------------------------------------------
#Generating sample from grid by design
samples = gridSampler(50, map,"regular", noise = 0.1)
#--------------------------------------------------------------------------------------------------------
# Fitting trend w.r.t. covariance matrix and sample position
correlation_sample = cbind(samples$x,samples$y)
glm_object = glmLite('quadratic', samples,
correlationMatrix(correlation_sample, correlation_sample,
range = 5, correlation_function = 'exponential'))
#--------------------------------------------------------------------------------------------------------
#Predicting the data with glm estimates of trend
posterior_distribution = posteriorDistribution(50, 50, glm_est=glm_object)
image.plot(posterior_distribution$prediction)
image.plot(posterior_distribution$variance)
#Source auxilliary functions
source('~/Documents/Bachelor/myglm_lite.R')
set.seed(4545)
#TODO:
# - Lage flere funksjoner for oversiktlighet
# - Gjennoms??ke myglm_lite
# - Begynne ?? notere i latex
# - Koble prior med prediksjonen
# - Unders??ke hvorfor 'linear' og 'quadratic' gir tilsynelatende motsatt resultater
par(mfrow=c(2,2))
#Adapting data from matrix form
original_mapping = grid.to.xyz(t(volcano))
image.plot(original_mapping)
map = squareMap(original_mapping, 50)
#--------------------------------------------------------------------------------------------------------
#Constructing priorfield
prior = priorField(10,10)
#--------------------------------------------------------------------------------------------------------
#Generating sample from grid by design
samples = gridSampler(50, map,"regular", noise = 0.1)
#--------------------------------------------------------------------------------------------------------
# Fitting trend w.r.t. covariance matrix and sample position
correlation_sample = cbind(samples$x,samples$y)
glm_object = glmLite('quadratic', samples,
correlationMatrix(correlation_sample, correlation_sample,
range = 5, correlation_function = 'exponential'))
#--------------------------------------------------------------------------------------------------------
#Predicting the data with glm estimates of trend
posterior_distribution = posteriorDistribution(50, 50, glm_est=glm_object)
image.plot(map)
image.plot(posterior_distribution$prediction)
image.plot(posterior_distribution$variance)
par(mfrow=c(1,1))
tempdata = read.table('~/Documents/Bachelor/tempdata.txt')
tempdata = read.table('~/Documents/Bachelor/tempdata.txt')
sail_lines = read.table('~/Documents/Bachelor/sail_lines.txt')
image.plot(tempdata)
source('~/Documents/Bachelor/auxiliary_function_procedure.R')
source('~/Documents/Bachelor/auxiliary_function_stats.R')
tempdata = read.table('~/Documents/Bachelor/tempdata.txt')
sail_lines = read.table('~/Documents/Bachelor/sail_lines.txt')
image.plot(tempdata)
?read.table
tempdata = read.table('~/Documents/Bachelor/tempdata.txt', header = TRUE)
image.plot(tempdata)
names(tempdata)
names(tempdata)[1] <- x
names(tempdata)[1] <- 'x'
names(tempdata)
names(tempdata)[2] <- 'y'
names(tempdata)[1] <- 'x'; names(tempdata)[2] <- 'y'; names(tempdata)[3] <- 'z'
image.plot(tempdata)
names(tempdata)[1] <- 'x'; names(tempdata)[2] <- 'y'; names(tempdata)[3] <- 'z'
image.plot(tempdata)
