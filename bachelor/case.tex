\section{Case}
\subsection{Case introduction}
\subsubsection{Introduction and case specification} \label{subsub:goals}
In this case I've been presented with the task of performing a predictive analysis of an attribute that may be modelled by a random field. The scenario is that there is a desire in knowing the temperature for a specific physical location, and one would like to perform predictive analysis with the following goals in mind:
\begin{itemize} 
\item Perform satisfactory accurate predictions
\item Minimize data acquirement needed
\end{itemize} 
In order to ensure that these goals will be met, the analysis of the case will be set up within the framework of a hierarchical model as described in (\ref{hm:linear_model}). Within this setting, suitable criterias must be set so that the analysis may be performed in a way that easily relates to these goals. The criterias set for this case will be to minimize equation (\ref{eq:criteria}) where the proposed paths focus on covering areas where the prediction variance is high. Informally we may say that we are seeking for the most uncertainty-reducing paths of data sampling. 

\subsubsection{Input}
The only information that we're presented with beforehand is a variogram computed on the basis of simulation model output based on weather forecasts, oceanographic models and satelite data. This is however reckoned as slightly unreliable data and must be handled accordingly. The area in which the analysis will be based on is given as a list of xy-coordinates with each coordinate being given a z-variable denoting the numerical value to the attribute of interest. There is a total of 29116 coordinates, ordered into a rectangular grid with size 116 in x-direction and size 251 in y-direction. The directions will informally be called easting and northing when plotting. The variogram is presented in (\ref{fig:variogram}) along with the original data which we desire to predict. 

\begin{figure}[p]
\minipage{0.45\textwidth}
	\includegraphics[width=1.4\linewidth]{figurer/variogram_covariancefunctions.png}
    \caption{Variogram given as input to the case.}
    \label{fig:variogram}
	\endminipage\hfill
	\minipage{0.45\textwidth}
  \includegraphics[width=1.4\linewidth]{figurer/original_reduced.png}
   \label{fig:original_data}
	 \caption{Actual data that are to be predicted on a reduced grid from the original.}
\endminipage
\end{figure}

\begin{figure}[p] 
\minipage{0.5\textwidth}
	\includegraphics[width=1\linewidth]{figurer/fitted_exponential.png}
     \caption{Fitted prior distribution for $\tau$.}
     \label{fittedexponential}
	\endminipage\hfill
	\minipage{0.5\textwidth}
  \includegraphics[width=1\linewidth]{figurer/fitted_gamma.png}
	 \caption{Fitted prior distribution for $\sigma^2$}
	 \label{fittedgamma}
\endminipage
\end{figure}

\subsubsection{Model specification and starting point of analysis} \label{subs:model}
As a necessary preliminary for the predictive analysis the temperature attribute of all the coordinates is modelled as a stochastic variable. Attaining a Gaussian process to describe trend and variability of model, the grid is viewed as a GRF. The connection between variables in this model will revolve around spatial location within the grid, where the trendfunction will be estimated by GLS regression on the sampled data. The covariance will be described by an isotropic, where results from all three covariancefunctions of (\ref{eq:covariance_functions}) will be presented individually. \\
The model process is fitted into the hierarchical model (HM) design described in (\ref{model:hm}). With $Y$ denoting the temperature variables at locations $\vec{s}$, that's set to be distributed according to the Gaussian process, the hierarchical model follows as
\begin{align*}
\begin{split}
\textbf{Data model: }& \vec{Z}(\vec{s}) = \vec{Y}(\vec{s}) + \vec{\epsilon}(\vec{s}), \quad \vec{\epsilon}(\vec{s}) \sim \mathcal{MVN} \big(\vec{0},\phi^2I(\vec{s}) \big) \\
\textbf{Process model: }& \vec{Y} = \vec{\mu} + \rho(\vec{s}), \quad \rho(\vec{s}) \sim \mathcal{MVN} \big(\vec{0}, \ C_Y(D(\vec{s}), \sigma^2, \tau ) \big) \\
\textbf{Prior model: }& \sigma^2 \sim \text{Gamma}(\alpha, \kappa), \quad \tau \sim \text{Exp}(\lambda)
\end{split}
\end{align*}
The intensity of the sampling noise, $\phi^2$, is the only one of the parameters that will be fixed. The motivation for doing so is that sampling noise may be viewed as more related to the equipment being used than the analysis in which it is included. Compared to the other parameters, one may have much more information about this parameter, as it may be stated by the equipment manufacturer or be tested separately in controlled environments. For the results, $\phi^2 = 0.2$ has been used. 

With the trend $\vec{\mu}$ is to be estimated by GLS on the sampled data eventually the data model is redefined as 
\begin{align} \label{eq:data_model}
\begin{split}
\textbf{Data model: }\vec{Z}(\vec{s}) &= X(\vec{s})\hat{\vec{\beta}} + \epsilon(\vec{s}) + \rho(\vec{s}) \\
\implies \vec{Z}(\vec{s}) &\sim \mathcal{MVN} \big( X(\vec{s})\hat{\vec{\beta}}, \ X(\vec{s}) \Sigma_{\hat{\beta}} X(\vec{s})^{T} + C_Y(D(\vec{s}), \sigma^2, \tau ) + \phi^2I(\vec{s}) \big)
\end{split}
\end{align}
where  Var${\hat{\beta}} = \Sigma_{\hat{\beta}} =  \bigg( X(\vec{s_0})^T \cdot \big( C_Y(D(\vec{s_0}), \sigma^2, \tau \big) + \phi^2I(\vec{s_0}) )^{-1} \cdot X(\vec{s_0}) \bigg)^{-1}$. \\

\subsection{Analysis}
\subsubsection{Choosing prior-parameters}
As a consequence of defining our model with prior-distributions for $\sigma^2$ and $\tau$, we must somehow estimate or choose parameters for their distributions. In order to do so, the variogram given as a part of the case preliminary has been utilized to estimate the GRF parameters of $\sigma^2$ and $\tau$. Given the three covariancefunctions in \ref{eq:covariance_functions}, the one may try to fit the the parameters of the chosen covariancefunction to the line. Denoting the discrete variogram values at points $k$ as $\gamma_k$ and the fitted covariancefunction at the same points as $\hat{\gamma}_k(\sigma^2, \tau)$, this is done by minimizing the associated lossfunction
\begin{equation}
Loss(\sigma^2, \tau) = \sum_k \bigg( \frac{\gamma_k - \hat{\gamma}_k(\sigma^2, \tau)}{\gamma_k} \bigg)^2
\end{equation}
Notice that we only have two parameters to be estimated for each covariancefunction as the nugget effect has been assumed to be negligible, resulting in more stable computation of fit. This minimization has been performed using the \textit{variofit} function in the \textit{geoR} package found in the programming environement R. Obviously, the covariance functions are exponentially decaying as a function of distance with the three chosen in \ref{eq:covariance_functions}. In order to visually compare the fit, we use the relation between the variogram of a isotropic process and its covariancefunction that is
\begin{align} \label{eq:variogram_covariancefunction}
\begin{split}
    2\gamma(\textbf{s},\textbf{t}) &= Var(Y(\textbf{s}) - Y(\textbf{t})) \\
    &= Var(Y(\textbf{s})) + Var(Y(\textbf{t})) - 2Cov(Y(\textbf{s}),Y(\textbf{t})) \\
    \implies \gamma(\textbf{s},\textbf{t}) &= \sigma^2 - Cov(\|\textbf{s}-\textbf{t}\|)
\end{split}
\end{align}

The variogram is then overlain with fitted covariancefunctions, adapted by equation (\ref{eq:variogram_covariancefunction}), from \ref{eq:covariance_functions} in figure (\ref{fig:variogram}).  

Denoting the estimated values as $\hat{\sigma}^2$ and $\hat{\tau}$, one could have performed predictioning straight away. However, in an attempt to reduce the uncertainty in using this variogram, $\hat{\sigma}^2$ and $\hat{\tau}$ is used to fit parameters for the priors. This has been done by using a \textit{method of moments} inspired approach. As we have a single parameter prior for $\tau$, its mean and variance is estimated by 
\begin{align}
\hat{\lambda} = \frac{1}{\hat{\tau}}
\end{align}
With $\sigma^2$ given a gamma-prior, one needs to estimate two parameters. Denoting $\sum_k (\gamma_k - \hat{\sigma}^2)^2$ as $s_*^2$, the following approximation is used to set parameters $\alpha$ and $\beta$:
\begin{align}
\mathbf{E}(\sigma^2) = \frac{\alpha}{\beta} \approx \hat{\sigma}^2, \quad
\mathbf{Var}(\sigma^2) = \frac{\alpha}{\beta^2} \approx s_*^2 
\implies 
\hat{\alpha} = \frac{(\hat{\sigma}^2)^2}{s_*^2}, \quad  \hat{\beta} = \frac{\hat{\sigma}^2}{s_*^2}
\end{align}

The resulting prior-distributions are presented in figures (\ref{fittedexponential}) and (\ref{fittedgamma}).

\subsubsection{Discretizing the prior domains}
As the analysis relies on a numerical summation over the prior domains, a strategy must be defined to discretize the domains into $n_{\sigma^2}$ and $n_{\tau}$ divisions used the summation \ref{eq:expected_variance_grf_posterior}. In this case a method of \textit{stratified sampling} has been used. Given size-input $n_{\sigma^2}$, $(0,\inf)$ is subdivided into $n_{\sigma^2}$ divisions, each part corresponding to a $\frac{1}{n_{\sigma^2}}$ probability mass of the prior. Random samples are simulated until minimum one sample within each division is obtained. The same procedure is performed for $n_{\tau}$. 

The joined domain of $\tau$ and $\sigma^2$ is then considered a grid, with each cell corresponding to samples $(\tau_i, \sigma_j^2)$ having a probability mass of $\Delta_{ij} = \frac{1}{n_{\sigma^2} \cdot n_{\tau}}$ due to independence of priors. With both the normalizing constaHowever, may also be definedt and the summation for predictioThis progame discretization, all $\Delta_{ij}$ cancels as they are independent of $(\tau_i, \sigma_j^2)$ and are therefore omitted from the calculations. A disadvantage is obviously the problem of simulating random samples for all the divisions if the number of divisions become high. However, $n_{\tau}$ and $n_{\sigma^2}$ is kept relatively low in this case. 

\subsubsection{Results}	
Due to time-limitations, only a select predefined designs were used to produce results. The designs are presented in figure (\ref{fig:designs}). 

As the model is reliant on estimation of trend, an initial data sample has to be obtained. To estimate the spatially averaged predictive standard deviation, each design presented in figure (\ref{fig:designs}) was used as an initial design. Samples was obtained from this initial design, and possible new designs for further predictive analysis of the area was the remaining sample designs. Using the procedure described in subsection (\ref{}), results are presented in the table below. Each number signifies the estimated spatially averaged standard deviation of using samples $Z$ from the design at the top of the table as the initial sample, with the design  on the left as the next path $Z_a$. 
\\

\hspace{-25pt}
\begin{tabular}{ l || c | c | c | c | c | c | c | c } 
\label{tab:bayes_predictive_variance}
$Z_a$ \textbackslash  $Z$ & Design 1 & Design 2 & Design 3 & Design 4 & Design 5 & Design 6 & Design 7 & Design 8 \\
\hline \hline
Design 1 & - & 548.0111 & 490.2626 & 472.2716 & \textbf{465.4389} & \textbf{461.4315} & \textbf{458.3172} & \textbf{457.1136} \\
Design 2 & 548.0420 & - & 549.6023 & 490.1057 & 473.6499 & 465.6733 & 460.4351 & 458.5897 \\
Design 3 & 490.2403 & 549.4966 & - & 547.7782 & 495.0345 & 474.8508 & 464.7677 & 461.2044 \\
Design 4 & 472.3915 & 490.0712 & 547.8146 & - & 580.9237 & 498.8230 & 473.9019 & 466.1729 \\
Design 5 & 465.5245 & 473.6227 & 495.0963 & 580.9661 & - & 573.4793 & 495.3815 & 476.5188 \\
Design 6 & 461.4052 & 465.4790 & 474.7950 & 498.7048 & 573.4010 & - & 555.6704 & 495.8328 \\
Design 7 & 458.3496 & 460.5030 & 464.8691 & 473.9674 & 495.4149 & 555.7863 & - & 559.4372 \\
Design 8 & \textbf{457.1382} & \textbf{458.4126} & \textbf{461.1775} & \textbf{466.1601} & 476.5174 & 495.9166 & 559.3891 & -
\end{tabular}

\begin{figure}[p]
	\hspace{-55pt}
	\includegraphics[width=1.25\linewidth]{figurer/design_lines.png}
    \caption{Sampling designs used to produce results.}
    \label{fig:designs}
\end{figure}